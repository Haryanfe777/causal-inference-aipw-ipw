# -*- coding: utf-8 -*-
"""SyntheticDataset.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1KcTVFCrDkC-rin9FmHE4CF7UZ_iuFzPr

# Pratical implementation Using Synthetic Dataset

pip install dowhy
"""

!pip install --upgrade scikit-learn econml dowhy
!pip install scikit-learn==1.0.2
!pip install econml[dowhy]
!pip install causalml
import sklearn
import econml
import dowhy
print(sklearn.__version__)  # Should be 1.0.2 or compatible
print(econml.__version__)    # Should be 0.15.1 or later
print(dowhy.__version__)     # Should be 0.9 or later

import numpy as np
import pandas as pd
import networkx as nx
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.linear_model import LogisticRegression, LinearRegression
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.preprocessing import StandardScaler
import dowhy
from dowhy import CausalModel
from econml.dml import CausalForestDML, LinearDML
from causalml.inference.meta import LRSRegressor, XGBTRegressor, MLPTRegressor

"""## Data Generation"""

# Seed for reproducibility
np.random.seed(42)

# Generate synthetic data
n_samples = 5000

#Synthetic dataset to mimics real-life scenarios

# Covariates
age = np.random.normal(60, 10, size=n_samples)  # Age, mean 60, std 10  drawn from a normal distribution
sex = np.random.binomial(1, 0.5, size=n_samples)  # Sex, binary  from a binomial distribution with ùëù=0.5  (0 = female, 1 = male)
heart_rate = np.random.normal(75, 10, size=n_samples)  # Baseline heart rate from normal distributions.
blood_pressure = np.random.normal(120, 15, size=n_samples)  # Baseline blood pressure from normal distributions

# Confounders
comorbidity_index = np.random.choice([0, 1, 2], size=n_samples, p=[0.5, 0.3, 0.2])  # 3 levels of severity: 0 (low severity), 1 (moderate severity), and 2 (high severity) with respective probabilities.
lifestyle_factors = np.random.binomial(1, 0.3, size=n_samples)  # Binary (1 = unhealthy lifestyle) 30% chance (probability ùëù=0.3) of unhealthy behavior

logits = (
    0.1 * (age - np.mean(age)) / np.std(age) +
    0.2 * (blood_pressure - np.mean(blood_pressure)) / np.std(blood_pressure) +
    0.2 * comorbidity_index +
    0.15 * lifestyle_factors
)
treatment_prob = 1 / (1 + np.exp(-logits))  # Sigmoid function

# Ensure that treatment assignment has both 0s and 1s
drug_administered = (treatment_prob > 0.5).astype(int)

# Outcome (Proarrhythmia Risk);linear combination of the treatment the covariates with some noises
proarrhythmia_risk = (
    0.5 * drug_administered
    + 0.4 * comorbidity_index
    + 0.3 * lifestyle_factors
    - 0.05 * heart_rate
    + 0.2 * sex
   + np.random.normal(0, 1.5, size=n_samples)  # Adding standard deviation of 1.5

)

drug_data = pd.DataFrame({
    "Age": age,
    "Sex": sex,
    "Heart_Rate": heart_rate,
    "Blood_Pressure": blood_pressure,
    "Comorbidity_Index": comorbidity_index,
    "Lifestyle_Factors": lifestyle_factors,
    "Treatment": drug_administered,
    "Outcome": proarrhythmia_risk
})

plt.figure(figsize=(8, 5))
sns.histplot(logits, bins=50, kde=True)
plt.title("Distribution of Logits")
plt.xlabel("Logits")
plt.ylabel("Count")
plt.show()

"""[texte du lien](https://)the chart shows the distribution of treatment assignment probabilities before applying the sigmoid function in your logistic treatment model. It shows that the treatment assignment model is well-calibrated, so individuals have a balanced spread of treatment probabilities."""

print(drug_data["Treatment"].value_counts(normalize=True))

drug_data2=drug_data.copy()

"""## DAG representation"""

# Create a DAG
dag = nx.DiGraph()
dag.add_nodes_from(["Age", "Sex", "Heart_Rate", "Blood_Pressure", "Comorbidity_Index", "Lifestyle_Factors", "Treatment", "Outcome"])
dag.add_edges_from([
    # Variables that affect Treatment
    ("Age", "Treatment"),
    ("Blood_Pressure", "Treatment"),
    ("Comorbidity_Index", "Treatment"),
    ("Lifestyle_Factors", "Treatment"),

    # Variables that affect Outcome
    ("Treatment", "Outcome"),
    ("Comorbidity_Index", "Outcome"),
    ("Lifestyle_Factors", "Outcome"),
    ("Sex", "Outcome"),
    ("Heart_Rate", "Outcome"),
])

# Plot the DAG
plt.figure(figsize=(10, 8))
nx.draw(dag, with_labels=True, node_color="lightblue", node_size=3500, font_size=12, font_weight="bold", arrowsize=20)
plt.title("Causal DAG for Synthetic Data", fontsize=16)
plt.show()

# Initialize the DoWhy causal model
Model = dowhy.CausalModel(
    data=drug_data,
    treatment="Treatment",
    outcome="Outcome",
    common_causes=["Comorbidity_Index", "Lifestyle_Factors"],  # Confounders
    effect_modifiers=["Sex", "Heart_Rate"],  # Variables affecting Outcome
    instruments=["Age", "Blood_Pressure"]  # Variables affecting only Treatment
)

# Visualize the causal graph
Model.view_model()

"""The causal model reflex all our assumptions about the dataset. it isualize assumptions about the causal structure and correctly  identify confounders, instrumental variables and effect_modifiers"""

# Identify the causal estimand
identified_estimand = Model.identify_effect(proceed_when_unidentifiable=True)
print(identified_estimand)

# Estimate the effect using propensity score weighting
causal_estimate_ipw = Model.estimate_effect(
    identified_estimand,
    method_name="backdoor.propensity_score_weighting",
    target_units="ate"
)
print(f"Estimated ATE using Propensity Score Weighting: {causal_estimate_ipw.value}")

"""The backdoor adjustment estimand assumes treatment assignment is unconfounded, so all confounders are measured and adjusted for.as expected, it uses Comorbidity_Index and Lifestyle_Factors as control variables to estimate the true causal effect. it uses Age and Blood Pressure act as instrumental variables and doesn't include any frontdoor adjustment because there are no mediators between Treatment ‚Üí Outcome in the DAG.


Estimated ATE  of IPW = 0.5316

This means that, on average, receiving treatment increases the outcome (Proarrhythmia Risk) by 0.53 units.

"""

subset_test = Model.refute_estimate(
    identified_estimand,
    causal_estimate_ipw,
    method_name="data_subset_refuter"
)
print(subset_test)

"""The ATE remained stable when we estimated the effect on only a subset of the data. It makes sense that the estimated effect isn't just due to outliers or data selection bias. The high P-Value also meaning the estimate is robust across different subsets."""

random_conf_test = Model.refute_estimate(
    identified_estimand,
    causal_estimate_ipw,
    method_name="random_common_cause"
)
print(random_conf_test)

"""When we added a random, fake confounder, the estimated effect did not change at all.It means that adding irrelevant variables doesn't change the result. The model is robust to irrelevant variables, and confounder control is working well. Also, higg P-Value.

"""

##CATE estimation.

# Define the condition for the covariates
condition = (drug_data2['Age'] > 45) & (drug_data2['Blood_Pressure'] > 90)

df_new = drug_data2[condition]

Model_cate = dowhy.CausalModel(
    data=df_new,
    treatment='Treatment',  # Treatment variable
    outcome='Outcome',     # Outcome variable
    common_causes=["Comorbidity_Index", "Lifestyle_Factors"],
    effect_modifiers=["Sex", "Heart_Rate"],
    instruments=["Age", "Blood_Pressure"]

)

# Visualize the causal graph
Model_cate.view_model()

cate_estimate = Model_cate.estimate_effect(
    identified_estimand=Model.identify_effect(),
    method_name="backdoor.propensity_score_weighting",
    control_value=0,
    treatment_value=1,
)


# Display the CATE estimate
print(f"Conditional Average Treatment Effect (CATE): {cate_estimate.value}")

"""### AIPW with Dowhy"""

from sklearn.linear_model import LogisticRegression

# Define the propensity score model
propensity_model = LogisticRegression()

# Estimate the effect using AIPW
causal_estimate_aipw = Model.estimate_effect(
    identified_estimand,
    method_name="backdoor.econml.dr.LinearDRLearner",  # AIPW-compatible method (Dowhy using EconML function)
    target_units="ate",
    method_params={
        "init_params": {
            "model_propensity": propensity_model,  # Pass the LogisticRegression object
            "model_regression": "forest"     # Outcome regression model
        },
        "fit_params": {}
    }
)

print(causal_estimate_aipw)

"""Estimated ATE (Mean Value) for AIPW = 0.4879
This means that receiving treatment increases the outcome (Proarrhythmia Risk) by ~0.49 units on average. AIPW is slightly lower than IPW (0.5316), which may indicate a better-adjusted model. There are also individual-level treatment effects, showing the model does not assume a single treatment effect for all individuals.

## Manual Implementation
"""

import numpy as np
import pandas as pd
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestRegressor

# Define covariates to match DoWhy's identified backdoor variables
covariates = ["Comorbidity_Index", "Lifestyle_Factors"]
X = drug_data[covariates]
Y = drug_data["Outcome"]
Treatment = drug_data["Treatment"].astype(int)

# Propensity score model (I realized that depending on the parameters, the output flunctuates)
propensity_model = LogisticRegression(solver='lbfgs', max_iter=1000, C=1.0, random_state=42)
propensity_model.fit(X, Treatment)
propensity = propensity_model.predict_proba(X)[:, 1]
propensity = np.clip(propensity, 1e-6, 1 - 1e-6)  # Clip

# Outcome models (separate for treated/untreated)
outcome_model_treated = RandomForestRegressor(n_estimators=100, random_state=42)
outcome_model_untreated = RandomForestRegressor(n_estimators=100, random_state=42)

# Fit on treated/untreated subsets
outcome_model_treated.fit(X[Treatment == 1], Y[Treatment == 1])
outcome_model_untreated.fit(X[Treatment == 0], Y[Treatment == 0])

# Predict potential outcomes for all
mu1 = outcome_model_treated.predict(X)
mu0 = outcome_model_untreated.predict(X)

# Compute AIPW
term1 = Treatment * (Y - mu1) / propensity
term2 = (1 - Treatment) * (Y - mu0) / (1 - propensity)
aipw_estimate = np.mean(term1 - term2 + mu1 - mu0)

# Compute IPW
ipw_estimate = np.mean((Treatment * Y / propensity) - ((1 - Treatment) * Y / (1 - propensity)))


print(f"IPW ATE: {ipw_estimate:.4f}")
print(f"AIPW ATE: {aipw_estimate:.4f}")

placebo_test_aipw = Model.refute_estimate(
    identified_estimand,
    estimate=causal_estimate_aipw,  # Using AIPW estimate
    method_name="placebo_treatment_refuter"
)

print("Placebo Treatment Test Result:")
print(placebo_test_aipw)

"""AIPW estimate drops from 0.4879 to 0.0105 when a fake treatment is used.
p-value = 0.8 ‚Üí No significant effect remains.
we can conclude that AIPW is valid because it detects no causal effect when treatment is randomized.
"""

#random_conf_test_aipw = Model.refute_estimate(
 #   identified_estimand,
  #  estimate=causal_estimate_aipw,
   # method_name="random_common_cause"
#)

#print("Random Common Cause Test Result:")
#print(random_conf_test_aipw)

subset_test_aipw = Model.refute_estimate(
    identified_estimand,
    estimate=causal_estimate_aipw,
    method_name="data_subset_refuter"
)

print("Subset Data Test Result:")
print(subset_test_aipw)

"""AIPW estimate changes slightly (0.4879 ‚Üí 0.4264) when using a random subset of the data.
p-value = 0.3 ‚Üí No strong evidence that the effect changed significantly.
so we can also conclude that AIPW is relatively stable but shows some sensitivity to sample size.

AIPW estimates passes all robustness checks

## More analysis

Calculating estimates with all covariates and each covariates one at a time
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestRegressor


# Define all covariates
all_covariates = ["Age", "Sex", "Heart_Rate", "Blood_Pressure", "Comorbidity_Index", "Lifestyle_Factors"]
X = drug_data[all_covariates]
Y = drug_data["Outcome"]
Treatment = drug_data["Treatment"].astype(int)

# Function to compute IPW estimate
def compute_ipw_estimate(X, Y, Treatment):
    # Propensity score model
    propensity_model = LogisticRegression(solver='lbfgs', max_iter=1000, C=1.0, random_state=42)
    propensity_model.fit(X, Treatment)
    propensity = propensity_model.predict_proba(X)[:, 1]
    propensity = np.clip(propensity, 1e-6, 1 - 1e-6)  # Clip to avoid extreme weights

    # Compute IPW ATE
    ipw_estimate = np.mean(
        (Treatment * Y / propensity) - ((1 - Treatment) * Y / (1 - propensity))
    )

    return ipw_estimate

# Function to compute AIPW estimate
def compute_aipw_estimate(X, Y, Treatment):
    # Propensity score model
    propensity_model = LogisticRegression(solver='lbfgs', max_iter=1000, C=0.1, random_state=42)
    propensity_model.fit(X, Treatment)
    propensity = propensity_model.predict_proba(X)[:, 1]
    propensity = np.clip(propensity, 1e-6, 1 - 1e-6)  # Clip to avoid extreme weights

    # Outcome models (separate for treated/untreated)
    outcome_model_treated = RandomForestRegressor(n_estimators=100, random_state=42)
    outcome_model_untreated = RandomForestRegressor(n_estimators=100, random_state=42)

    # Fit on treated/untreated subsets
    outcome_model_treated.fit(X[Treatment == 1], Y[Treatment == 1])
    outcome_model_untreated.fit(X[Treatment == 0], Y[Treatment == 0])

    # Predict potential outcomes for all
    mu1 = outcome_model_treated.predict(X)
    mu0 = outcome_model_untreated.predict(X)

    # Compute AIPW
    term1 = Treatment * (Y - mu1) / propensity
    term2 = (1 - Treatment) * (Y - mu0) / (1 - propensity)
    aipw_estimate = np.mean(term1 - term2 + mu1 - mu0)

    return aipw_estimate

# Compute causal estimates for all covariates
ipw_all_covariates = compute_ipw_estimate(X, Y, Treatment)
aipw_all_covariates = compute_aipw_estimate(X, Y, Treatment)

# Compute causal estimates for single covariates
ipw_single_covariates = {}
aipw_single_covariates = {}

for covariate in all_covariates:
    X_single = drug_data[[covariate]]  # Use only one covariate
    ipw_single_covariates[covariate] = compute_ipw_estimate(X_single, Y, Treatment)
    aipw_single_covariates[covariate] = compute_aipw_estimate(X_single, Y, Treatment)

# plotting
covariates_list = all_covariates + ["All Covariates"]
ipw_estimates = [ipw_single_covariates[cov] for cov in all_covariates] + [ipw_all_covariates]
aipw_estimates = [aipw_single_covariates[cov] for cov in all_covariates] + [aipw_all_covariates]

# Plot the results
x = np.arange(len(covariates_list))  # the label locations
width = 0.35  # the width of the bars

fig, ax = plt.subplots(figsize=(12, 6))
rects1 = ax.bar(x - width/2, ipw_estimates, width, label='IPW')
rects2 = ax.bar(x + width/2, aipw_estimates, width, label='AIPW')

# Add labels, title, and custom x-axis tick labels
ax.set_xlabel('Covariates')
ax.set_ylabel('Causal Estimate (ATE)')
ax.set_title('Causal Estimates Using Single and All Covariates (IPW vs. AIPW)')
ax.set_xticks(x)
ax.set_xticklabels(covariates_list, rotation=45, ha='right')
ax.legend()

# Add value labels on top of the bars
def autolabel(rects):
    for rect in rects:
        height = rect.get_height()
        ax.annotate(f'{height:.3f}',
                    xy=(rect.get_x() + rect.get_width() / 2, height),
                    xytext=(0, 3),  # 3 points vertical offset
                    textcoords="offset points",
                    ha='center', va='bottom')

autolabel(rects1)
autolabel(rects2)

fig.tight_layout()
plt.show()

"""1. we can see that each covariate individually has a similar effect on the treatment and outcome and there are no strong interactions between covariates that significantly alter the treatment effect.

The AIPW estimates are more consistent across single covariates and all covariates. AIPW is doubly robust, so it remains consistent if either the propensity score model or the outcome model is correctly specified. it is generally more stable than IPW, especially when the propensity scores are extreme.

For IPW, A negative ate estimate with all covariates is unusual, especially when the single-covariate IPW estimates are all positive.

### Other frameworks

### Causal ML
"""

#CausalML
import numpy as np
import pandas as pd
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestRegressor
from econml.dml import CausalForestDML

# Define all covariates
covariates = ["Comorbidity_Index", "Lifestyle_Factors"]
X = drug_data[covariates]
Y = drug_data["Outcome"]
Treatment = drug_data["Treatment"].astype(int)

# Causal Forest Estimator for ATE (using Double Machine Learning)
causal_forest = CausalForestDML(
    model_t=RandomForestRegressor(n_estimators=100, random_state=42),  # model for treatment effect
    model_y=RandomForestRegressor(n_estimators=100, random_state=42),  # model for outcome
    discrete_treatment=True,  # if treatment is binary
    random_state=42
)

# Fit the model
causal_forest.fit(Y, Treatment, X=X)

# Estimate the ATE
ate = causal_forest.ate(X)

# Print results
print(f" AIPW Causal Forest ATE (CausalML): {ate:.4f}")

"""### EconML"""

#EconML
import numpy as np
import pandas as pd
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestRegressor
from econml.dml import LinearDML
# Define the treatment, outcome, and covariates
X = drug_data[["Comorbidity_Index", "Lifestyle_Factors"]].values  # Covariates
Treatment = drug_data['Treatment'].values  # Treatment (Drug Administered)
Y = drug_data['Outcome'].values  # Outcome (Proarrhythmia Risk)



# Define the propensity score model
model_pscore = RandomForestRegressor(n_estimators=100, random_state=42)

# Fit the model to predict treatment assignment
model_pscore.fit(X, Treatment)

from sklearn.ensemble import RandomForestRegressor

# Define the outcome model
model_outcome = RandomForestRegressor(n_estimators=100, random_state=42)

# Fit the model to predict the outcome
model_outcome.fit(X, Y)


# Define the AIPW model (DML model for ATE estimation)
dml = LinearDML(model_y=model_outcome, model_t=model_pscore, random_state=42)

# Fit the model (DML for AIPW estimation)
dml.fit(Y, Treatment, X=X)

# Estimate the ATE using the model
ate_estimate = dml.effect(X).mean()
print(f"Estimated ATE (AIPW) for EconML: {ate_estimate}")

"""All the frameworks produce similar estimates with only slight differences(within ~0.05 range). We can deduce that the different framworks are likely capturing the true treatment effect.

### Comparing Regressors
"""

# Define all covariates
all_covariates = ["Comorbidity_Index", "Lifestyle_Factors"]
X = drug_data[all_covariates]
Y = drug_data["Outcome"]
Treatment = drug_data["Treatment"].astype(int)

# Define different models
propensity_models = {
    "Logistic Regression": LogisticRegression(solver='lbfgs', max_iter=1000, C=1.0, random_state=42),
    # Only classification models can be used for propensity scores
}

outcome_models = {
    "Linear Regression": LinearRegression(),
    "Random Forest": RandomForestRegressor(n_estimators=100, random_state=42),
    "Gradient Boosting": GradientBoostingRegressor(n_estimators=100, random_state=42),
}

# Function to compute IPW manually
def compute_ipw_estimate(X, Y, Treatment, propensity_model):
    # Fit propensity score model
    propensity_model.fit(X, Treatment)
    propensity_scores = propensity_model.predict_proba(X)[:, 1]

    # Clip propensity scores to avoid extreme values
    propensity_scores = np.clip(propensity_scores, 1e-6, 1 - 1e-6)

    # Compute IPW weights
    weights = np.where(
        Treatment == 1,
        1 / propensity_scores,
        1 / (1 - propensity_scores)
    )

    # Compute IPW ATE
    ipw_ate = np.mean(
        (Treatment * Y / propensity_scores) - ((1 - Treatment) * Y / (1 - propensity_scores))
    )

    return ipw_ate

# Compute IPW and AIPW estimates for each combination of models
results = []

for p_name, p_model in propensity_models.items():
    for o_name, o_model in outcome_models.items():
        # IPW
        ipw_ate = compute_ipw_estimate(X, Y, Treatment, p_model)

        # AIPW (using CausalML's meta-learners)
        if o_name == "Linear Regression":
            aipw_estimator = LRSRegressor()
        elif o_name == "Random Forest":
            aipw_estimator = XGBTRegressor()
        elif o_name == "Gradient Boosting":
            aipw_estimator = MLPTRegressor()

        aipw_ate = aipw_estimator.estimate_ate(X, Treatment, Y)

        # Store results
        results.append({
            "Propensity Model": p_name,
            "Outcome Model": o_name,
            "IPW ATE": ipw_ate,
            "AIPW ATE": aipw_ate[0],  # Extract the ATE value
        })

# Display results
results_df = pd.DataFrame(results)
print(results_df)

"""Only LogisticRegression is used for the propensity score model because it is a classification model. All models (LinearRegression, RandomForestRegressor, GradientBoostingRegressor) are regression models and can be used for the outcome.

From the results, we can see that IPW estimates are consistent across all propensity score models, whhich shows robustness to the choice of the propensity score model.

The AIPW estimates vary depending on the outcome model. We can see that:

Linear Regression (0.4837) ‚Üí Slightly overestimates the effect.
Random Forest (0.4416) ‚Üí Produces the lowest ATE, possibly due to better non-linearity handling.
Gradient Boosting (0.4701) ‚Üí Close to Linear Regression but more flexible in capturing interactions.


The choice of the outcome model has a larger impact on the AIPW estimate than the choice of the propensity score model.

## Conclusion

This study aimed to estimate the causal effect of treatment on Proarrhythmia Risk using two main methods:Inverse Probability Weighting (IPW) $ Augmented Inverse Probability Weighting (AIPW)
We experimented with different modeling choices for propensity score estimation and outcome regression models, while also conducting robustness checks to validate the reliability of our estimates.

**Strengths and Weaknesses of Both Methods:**

*IPW* \
‚úÖ Simple and unbiased under correct model specification. \
‚úÖ Effective for reducing confounding using propensity scores. \
‚ùå High variance when propensity scores are extreme. \
‚ùå Sensitive to poor overlap in treatment probabilities.

*AIPW*
‚úÖ Lower variance by using outcome models. \
‚úÖ More efficient than IPW. \
‚úÖ More robust to poor propensity score overlap.
‚ùå Model choice affects results.


**Results Interpretation and Observations**: \
1. IPW Estimates Are Higher than AIPW . IPW is likely overestimating the effect due to higher sensitivity to extreme weights
2. AIPW is more robust since it combines propensity scores and outcome models to correct for variance. It produces better estimates with lower variance.
3. Robustness Checks Confirm our techniques Validity
4. AIPW is sensitive to the choice of outcome models. Different Outcome Models produce different results and Random Forest produced the lowest values.
5. All frameworks(Dowhy, Econml, CausalMl) give similar estimate values.


**Final Verdict**:
IPW works well when treatment probabilities are well-distributed and there is strong overlap between treated and untreated groups. \
AIPW is preferred because it reduces variance and adjusts for model misspecification, making it a more robust estimator. \

The choice of outcome model impacts AIPW estimates, with Random Forest providing the most conservative estimate and Linear Regression producing the highest.
"""

